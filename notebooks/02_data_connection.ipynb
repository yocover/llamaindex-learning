{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")  # 添加父目录到 Python 路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "\n",
    "def format_response(response):\n",
    "    \"\"\"Format the response with proper styling and structure.\"\"\"\n",
    "    from IPython.display import display, Markdown\n",
    "    import re\n",
    "    \n",
    "    # Convert the response to string if it's not already\n",
    "    content = str(response)\n",
    "    \n",
    "    # Process the content to improve readability\n",
    "    # 1. Split into sentences and add line breaks\n",
    "    sentences = content.replace('。', '。\\n\\n')\n",
    "    sentences = sentences.replace('！', '！\\n\\n')\n",
    "    sentences = sentences.replace('？', '？\\n\\n')\n",
    "    \n",
    "    # 2. Handle lists and enumerations\n",
    "    sentences = re.sub(r'(\\d+[\\.、])', r'\\n\\1', sentences)\n",
    "    \n",
    "    # 3. Handle special punctuation for Chinese text\n",
    "    sentences = sentences.replace('：', '：\\n')\n",
    "    sentences = sentences.replace('；', '；\\n')\n",
    "    \n",
    "    # 4. Clean up multiple newlines\n",
    "    sentences = re.sub(r'\\n\\s*\\n', '\\n\\n', sentences)\n",
    "    \n",
    "    # Add markdown styling with better spacing\n",
    "    formatted_text = f\"\"\"\n",
    "### 查询结果\n",
    "\n",
    "{sentences.strip()}\n",
    "\n",
    "---\n",
    "*Generated by LlamaIndex RAG System*\n",
    "\"\"\"\n",
    "    \n",
    "    # Display as markdown for better formatting\n",
    "    display(Markdown(formatted_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "### 查询结果\n",
       "\n",
       "你好！\n",
       "\n",
       "我是来自阿里云的大规模语言模型，我叫通义千问。\n",
       "\n",
       "我是阿里云自主研发的超大规模语言模型，能够回答问题、创作文字，还能表达观点、撰写代码。\n",
       "\n",
       "如果您有任何问题或需要帮助，请随时告诉我，我会尽力提供支持。\n",
       "\n",
       "---\n",
       "*Generated by LlamaIndex RAG System*\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.llms.siliconflow import SiliconflowLLM\n",
    "from llama_index.core import Settings\n",
    "\n",
    "\n",
    "api_key = \"sk-gxjqtuvbqdcmuicsazotvnvuzpvaqpukrjwcisumxytblhxx\"\n",
    "\n",
    "\n",
    "llm = SiliconflowLLM(\n",
    "    api_key=api_key,\n",
    "    api_base=\"https://api.siliconflow.cn/v1\",\n",
    "    model_name=\"Qwen/Qwen2.5-VL-72B-Instruct\",\n",
    ")\n",
    "\n",
    "res = llm.complete(\"你好，介绍一下自己？\")\n",
    "# print(res.text)  # 使用 flush=True 确保立即输出\n",
    "format_response(res)\n",
    "\n",
    "Settings.llm = llm\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512 32\n",
      "BAAI/bge-large-en-v1.5\n"
     ]
    }
   ],
   "source": [
    "# 设置 embedding 模型, 这里我门使用自定义的硅流embedding\n",
    "from llama_index.core import Settings\n",
    "from src.embeddings.siliconflow import SiliconflowEmbedding\n",
    "\n",
    "\n",
    "api_key = \"sk-gxjqtuvbqdcmuicsazotvnvuzpvaqpukrjwcisumxytblhxx\"\n",
    "model_name = \"BAAI/bge-large-en-v1.5\"\n",
    "Settings.embed_model = SiliconflowEmbedding(\n",
    "    model_name=model_name, api_key=api_key, embed_batch_size=100\n",
    ")\n",
    "\n",
    "Settings.chunk_size = 512\n",
    "Settings.chunk_overlap = 32\n",
    "\n",
    "print(Settings.chunk_size, Settings.chunk_overlap)\n",
    "print(Settings.embed_model.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "### 查询结果\n",
       "\n",
       "数据构建完成！\n",
       "\n",
       "---\n",
       "*Generated by LlamaIndex RAG System*\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "# 加载文档\n",
    "documents = SimpleDirectoryReader(\"../data/xlsx/\").load_data()\n",
    "\n",
    "# 创建索引\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "\n",
    "# 创建查询引擎\n",
    "query_engine = index.as_query_engine()\n",
    "\n",
    "format_response(\"数据构建完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "### 查询结果\n",
       "\n",
       "阳台所用材料的总耗费为\n",
       "44448.26元中的部分，具体计算如下：\n",
       "\n",
       "- 柜体：\n",
       "\n",
       "4.176平方米，使用生态澳松板。\n",
       "\n",
       "- 门板：\n",
       "\n",
       "4.176平方米，使用进口PET。\n",
       "\n",
       "- 拉手：\n",
       "4个，单价680元，总价2720元。\n",
       "\n",
       "- 铰链：\n",
       "16个，单价60元，总价960元。\n",
       "\n",
       "由于柜体和门板的单价未直接给出，我们只能计算给出单价的部分：\n",
       "\n",
       "- 拉手总价：\n",
       "2720元\n",
       "- 铰链总价：\n",
       "960元\n",
       "\n",
       "因此，阳台所用材料中可计算的部分总耗费为2720元 + 960元 = 3680元。\n",
       "\n",
       "柜体和门板的总耗费需要根据单价计算，但单价信息未提供，所以这部分无法计算。\n",
       "\n",
       "如果需要完整计算阳台的总耗费，需要补充柜体和门板的单价信息。\n",
       "\n",
       "---\n",
       "*Generated by LlamaIndex RAG System*\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine.query(\"阳台所用材料一共耗费多少钱?\")\n",
    "format_response(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "### 查询结果\n",
       "\n",
       "The current assets for 2023 are 1,880,\n",
       "000. This figure is derived from the sum of the current assets listed, which includes Cash, Accounts receivable, and Inventory.\n",
       "\n",
       "---\n",
       "*Generated by LlamaIndex RAG System*\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine.query(\"What's the 2023's current assets?\")\n",
    "format_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "### 查询结果\n",
       "\n",
       "The provided information does not specify the year 2024 or any financial data associated with that year. Therefore, it's not possible to determine the current assets for 2024 based on the given details. The data provided includes figures for current assets such as cash, accounts receivable, and inventory, but without a specific year mentioned, these cannot be attributed to \n",
       "2024.\n",
       "\n",
       "---\n",
       "*Generated by LlamaIndex RAG System*\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine.query(\"What's the 2024's current assets?\")\n",
    "format_response(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
